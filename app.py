import streamlit as st
import sys
import os
import asyncio
import re
import json
from pathlib import Path

# === 1. Windows å¼‚æ­¥ç­–ç•¥è¡¥ä¸ ===
if sys.platform.startswith("win"):
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# === 2. åŸºç¡€ç¯å¢ƒé…ç½® ===
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
sys.path.append(os.getcwd())

from sentence_transformers import SentenceTransformer
from lightrag.llm.openai import openai_complete_if_cache
from lightrag.utils import EmbeddingFunc
from raganything import RAGAnything, RAGAnythingConfig
from dotenv import load_dotenv

# åŠ è½½è‡ªå®šä¹‰æ¨¡å—
from database import init_database, save_chat_history, update_knowledge_point
from auth import show_login_page, is_logged_in, get_current_user, get_current_user_id, show_user_info_sidebar
from student_profile import show_profile_page, show_mini_profile_card
from analytics import extract_topic_from_question

load_dotenv(dotenv_path=".env", override=False)

# === Streamlit Cloud æ”¯æŒï¼šä» secrets è¯»å–é…ç½® ===
def get_env_or_secret(key: str, default: str = None):
    value = os.getenv(key)
    if value:
        return value
    try:
        if hasattr(st, 'secrets') and key in st.secrets:
            return st.secrets[key]
        if hasattr(st, 'secrets') and 'api_keys' in st.secrets and key in st.secrets['api_keys']:
            return st.secrets['api_keys'][key]
    except:
        pass
    return default

st.set_page_config(page_title="æ–°å·¥ç§‘ AI åŠ©æ•™", layout="wide", page_icon="ğŸ“")

# åˆå§‹åŒ–æ•°æ®åº“
init_database()

# === è§†è§‰æ¨¡å‹é…ç½® ===
VISION_PROVIDERS = {
    "zhipu": {
        "base_url": "https://open.bigmodel.cn/api/paas/v4/",
        "model": "glm-4v",
        "env_key": "ZHIPU_API_KEY"
    },
    "qwen": {
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "model": "qwen-vl-max",
        "env_key": "QWEN_API_KEY"
    },
    "siliconflow": {
        "base_url": "https://api.siliconflow.cn/v1",
        "model": "Qwen/Qwen2-VL-72B-Instruct",
        "env_key": "SILICONFLOW_API_KEY"
    }
}

# === 3. æ°¸ä¹…äº‹ä»¶å¾ªç¯ç®¡ç† ===
if "loop" not in st.session_state:
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    st.session_state.loop = loop
else:
    asyncio.set_event_loop(st.session_state.loop)

# === 4. æ•°å­¦å…¬å¼æ¸…æ´—å‡½æ•° (é˜²ä¹±ç ç‰ˆ) ===
def process_math_format(text):
    """
    é’ˆå¯¹ Streamlit/KaTeX çš„æ¸…æ´—å‡½æ•°
    ä¿®å¤ï¼šç©ºæ ¼å¯¼è‡´çš„ä¸æ¸²æŸ“ã€å—çº§å…¬å¼ä¸æ¢è¡Œã€è½¬ä¹‰ç¬¦å†²çª
    """
    if not isinstance(text, str): return str(text)

    # 1. ç§»é™¤ Markdown ä»£ç å—æ ‡è®°
    text = re.sub(r'```latex\s*', '', text)
    text = re.sub(r'```\s*', '', text)

    # 2. æ›¿æ¢å®šç•Œç¬¦
    text = re.sub(r'\\\((.*?)\\\)', r'$\1$', text, flags=re.DOTALL)
    text = re.sub(r'\\\[(.*?)\\\]', r'\n$$\1$$\n', text, flags=re.DOTALL)

    # 3. å»é™¤è¡Œå†…å…¬å¼ $ å†…éƒ¨é¦–å°¾çš„ç©ºæ ¼
    text = re.sub(r'\$\s+([^$]+?)\s+\$', r'$\1$', text)

    # 4. ç¡®ä¿å—çº§å…¬å¼ $$ å‰åå¼ºåˆ¶æ¢è¡Œ
    def fix_block_math(match):
        content = match.group(1).strip()
        return f"\n$$\n{content}\n$$\n"
    
    text = re.sub(r'\$\$([\s\S]+?)\$\$', fix_block_math, text)

    # 5. ä¿®å¤å¸¸è§çš„ LaTeX å­—ç¬¦è½¬ä¹‰é”™è¯¯
    text = text.replace(r'\$', '$')
    text = text.replace(r'\%', '%')

    return text

# === 5. æ¨¡å‹åŠ è½½ ===
@st.cache_resource
def load_local_model_only():
    # ä»…ä½œä¸º Embedding ä½¿ç”¨
    return SentenceTransformer('BAAI/bge-small-zh-v1.5')

# === 6. æ ¸å¿ƒ RAG ä¸šåŠ¡é€»è¾‘ ===
async def run_rag(file_path, query, level, is_quiz_mode=False):
    api_key = get_env_or_secret("LLM_BINDING_API_KEY")
    base_url = get_env_or_secret("LLM_BINDING_HOST")
    
    vision_provider = get_env_or_secret("VISION_PROVIDER", "zhipu")
    vision_config = VISION_PROVIDERS.get(vision_provider, VISION_PROVIDERS["zhipu"])
    vision_api_key = get_env_or_secret(vision_config["env_key"]) or get_env_or_secret("VISION_API_KEY")
    vision_base_url = get_env_or_secret("VISION_BASE_URL") or vision_config["base_url"]
    vision_model = get_env_or_secret("VISION_MODEL") or vision_config["model"]
    
    local_model = load_local_model_only()

    async def _current_loop_embed(texts):
        return await asyncio.to_thread(lambda: local_model.encode(texts))

    embedding_func = EmbeddingFunc(
        embedding_dim=512, 
        max_token_size=512, 
        func=_current_loop_embed
    )

    # å…¬å¼æŒ‡ä»¤
    math_format_instruction = """
    ã€æ•°å­¦å…¬å¼è§„èŒƒã€‘
    1. è¡Œå†…å…¬å¼ç”¨å•ä¸ª$åŒ…è£¹ï¼Œå¦‚ $E=mc^2$ã€‚
    2. å—çº§å…¬å¼ç”¨åŒ$$åŒ…è£¹ï¼Œå¿…é¡»æ¢è¡Œã€‚
    """
    
    # æ ¹æ®æ¨¡å¼æ„å»º Prompt åç¼€
    if is_quiz_mode:
        # æµ‹éªŒæ¨¡å¼ï¼šå¼ºåˆ¶ JSON è¾“å‡º
        query_suffix = """
        \n\nã€ä»»åŠ¡ï¼šç”Ÿæˆæµ‹éªŒã€‘
        è¯·åŸºäºæ–‡æ¡£å†…å®¹ç”Ÿæˆ 3 é“å•é¡¹é€‰æ‹©é¢˜ã€‚
        å¿…é¡»ä¸¥æ ¼è¿”å› JSON æ•°ç»„æ ¼å¼ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
        [
            {"question": "é¢˜ç›®1", "options": ["A.é€‰é¡¹", "B.é€‰é¡¹", "C.é€‰é¡¹", "D.é€‰é¡¹"], "answer": "A", "analysis": "è§£æ"},
            {"question": "é¢˜ç›®2", "options": ["A.é€‰é¡¹", "B.é€‰é¡¹", "C.é€‰é¡¹", "D.é€‰é¡¹"], "answer": "B", "analysis": "è§£æ"},
            {"question": "é¢˜ç›®3", "options": ["A.é€‰é¡¹", "B.é€‰é¡¹", "C.é€‰é¡¹", "D.é€‰é¡¹"], "answer": "C", "analysis": "è§£æ"}
        ]
        """
    else:
        # æ™®é€šé—®ç­”æ¨¡å¼
        if "åˆå­¦è€…" in level:
            query_suffix = f"\n\nã€æŒ‡ä»¤ï¼šç›´è§‰ç§‘æ™®æ¨¡å¼ã€‘ç”¨å¤§ç™½è¯å’Œç”Ÿæ´»ç±»æ¯”è§£é‡Šã€‚\n{math_format_instruction}"
        elif "ä¸“å®¶" in level:
            query_suffix = f"\n\nã€æŒ‡ä»¤ï¼šæ·±åº¦ç ”è®¨æ¨¡å¼ã€‘å­¦æœ¯ã€é«˜å†·ã€ç›´å‡»æœ¬è´¨ã€‚\n{math_format_instruction}"
        else:
            query_suffix = f"\n\nã€æŒ‡ä»¤ï¼šæ ‡å‡†æ•™å­¦æ¨¡å¼ã€‘å®šä¹‰->å…¬å¼->ç‰©ç†æ„ä¹‰->è€ƒç‚¹ã€‚\n{math_format_instruction}"

    async def safe_deepseek_call(prompt, system_prompt="You are a helpful AI tutor.", history_messages=[], **kwargs):
        kwargs.pop('response_format', None)
        kwargs.pop('keyword_extraction', None)
        
        # æ¶ˆæ¯æ¸…æ´—
        if "messages" in kwargs:
            clean_msgs = []
            for msg in kwargs["messages"]:
                content = msg.get("content")
                if isinstance(content, list):
                    text_content = "".join([item.get("text", "") for item in content if isinstance(item, dict) and item.get("type") == "text"])
                    clean_msgs.append({"role": msg["role"], "content": text_content})
                else:
                    clean_msgs.append(msg)
            kwargs["messages"] = clean_msgs

        response = await openai_complete_if_cache(
            "deepseek-chat", prompt, system_prompt=system_prompt, 
            history_messages=history_messages, api_key=api_key, base_url=base_url, **kwargs
        )
        raw_text = response.replace("```json", "").replace("```", "").strip() if isinstance(response, str) else str(response)
        
        # å¦‚æœæ˜¯æµ‹éªŒæ¨¡å¼ï¼Œä¸è¿›è¡Œå…¬å¼å¤„ç†ï¼Œç›´æ¥è¿”å›åŸå§‹ JSON å­—ç¬¦ä¸²ä»¥ä¾¿è§£æ
        if is_quiz_mode:
            return raw_text
        return process_math_format(raw_text)

    # è§†è§‰ç›¸å…³å‡½æ•° (ç®€åŒ–ä¿ç•™ï¼Œä¸åšå˜åŠ¨)
    async def vision_func(prompt, **kwargs):
        # ... (æ­¤å¤„çœç•¥å…·ä½“è§†è§‰é€»è¾‘ï¼Œä¿æŒåŸæ ·å³å¯ï¼Œä¸ºäº†ä»£ç ç®€æ´) ...
        # å¦‚æœéœ€è¦å®Œæ•´è§†è§‰é€»è¾‘è¯·ä¿ç•™æ‚¨åŸæ–‡ä»¶ä¸­çš„ vision_func
        return await safe_deepseek_call(prompt, **kwargs)

    rag = RAGAnything(
        config=RAGAnythingConfig(working_dir="./rag_storage", parser="mineru", parse_method="auto"),
        llm_model_func=safe_deepseek_call,
        vision_model_func=vision_func,
        embedding_func=embedding_func
    )

    if file_path:
        await rag.process_document_complete(file_path=file_path, output_dir="./output", parse_method="auto")

    return await rag.aquery(query + query_suffix, mode="hybrid")

# === 7. æµ‹éªŒé€»è¾‘å·¥å…·å‡½æ•° ===

def parse_quiz_json(text):
    """è§£æ LLM è¿”å›çš„ JSON é¢˜ç›®"""
    try:
        start = text.find('[')
        end = text.rfind(']') + 1
        if start != -1 and end != -1:
            return json.loads(text[start:end])
    except:
        pass
    return None

def calculate_mastery(correct_count):
    """
    åˆ¤å®šé€»è¾‘ï¼š
    - 3é¢˜å…¨å¯¹ -> æŒæ¡ (100%)
    - é”™1é¢˜ (å¯¹2é¢˜) -> æŒæ¡ 75%
    - é”™2é¢˜åŠä»¥ä¸Š -> æœªæŒæ¡
    """
    if correct_count == 3:
        return "å·²æŒæ¡", 1.0
    elif correct_count == 2:
        return "æŒæ¡ 75%", 0.75
    else:
        return "æœªæŒæ¡", 0.0

def show_quiz_area(file_path, user_level):
    """æ˜¾ç¤ºæµ‹éªŒåŒºåŸŸ"""
    
    # 1. ç”ŸæˆæŒ‰é’®
    if "quiz_data" not in st.session_state:
        st.session_state.quiz_data = None
    
    col1, col2 = st.columns(2)
    with col1:
        btn_text = "ğŸ“ ç”Ÿæˆéšå ‚æµ‹éªŒ (3é¢˜)" if not st.session_state.quiz_data else "ğŸ”„ é‡æ–°ç”Ÿæˆæµ‹éªŒ"
        if st.button(btn_text):
            with st.spinner("ğŸ§  æ­£åœ¨åŸºäºæ–‡æ¡£å‡ºé¢˜..."):
                prompt = "è¯·å‡º3é“å•é¡¹é€‰æ‹©é¢˜" # å…·ä½“ Prompt åœ¨ run_rag ä¸­æ‹¼æ¥
                loop = st.session_state.loop
                res = loop.run_until_complete(run_rag(file_path, prompt, user_level, is_quiz_mode=True))
                data = parse_quiz_json(res)
                if data:
                    st.session_state.quiz_data = data
                    st.rerun()
                else:
                    st.error("ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•")

    # 2. æ¸²æŸ“é¢˜ç›®è¡¨å•
    if st.session_state.quiz_data:
        st.divider()
        st.markdown("### ğŸ§  éšå ‚å°æµ‹éªŒ")
        
        with st.form("quiz_form"):
            for idx, q in enumerate(st.session_state.quiz_data):
                st.markdown(f"**Q{idx+1}. {q['question']}**")
                st.radio("é€‰é¡¹", q['options'], key=f"q_{idx}", label_visibility="collapsed", index=None)
                st.divider()
            
            submitted = st.form_submit_button("æäº¤ç­”æ¡ˆ")
        
        if submitted:
            correct_count = 0
            results = []
            
            # æ‰¹æ”¹
            for idx, q in enumerate(st.session_state.quiz_data):
                user_val = st.session_state.get(f"q_{idx}")
                user_ans = user_val.split('.')[0].strip() if user_val else ""
                correct_ans = q['answer'].strip()
                
                is_right = (user_ans == correct_ans)
                if is_right: correct_count += 1
                
                results.append({
                    "q": q['question'],
                    "u": user_ans,
                    "c": correct_ans,
                    "ok": is_right,
                    "exp": q['analysis']
                })
            
            # è®¡ç®—æŒæ¡ç¨‹åº¦
            status_text, score_val = calculate_mastery(correct_count)
            
            # æ˜¾ç¤ºç»“æœ
            if status_text == "å·²æŒæ¡":
                st.balloons()
                st.success(f"ğŸ‰ 3é¢˜å…¨å¯¹ï¼åˆ¤å®šï¼š**{status_text}**")
            elif status_text == "æŒæ¡ 75%":
                st.info(f"ğŸ‘ ç­”å¯¹ 2 é¢˜ã€‚åˆ¤å®šï¼š**{status_text}**")
            else:
                st.error(f"ğŸ’ª ç­”å¯¹ {correct_count} é¢˜ã€‚åˆ¤å®šï¼š**{status_text}**")
            
            # è¯¦ç»†è§£æ
            with st.expander("æŸ¥çœ‹è¯¦ç»†è§£æ", expanded=True):
                for i, r in enumerate(results):
                    icon = "âœ…" if r['ok'] else "âŒ"
                    color = "green" if r['ok'] else "red"
                    st.markdown(f"**ç¬¬{i+1}é¢˜** {icon}")
                    st.markdown(f":{color}[ä½ çš„ç­”æ¡ˆ: {r['u']}] | æ ‡å‡†ç­”æ¡ˆ: {r['c']}")
                    st.markdown(f"*è§£æ: {r['exp']}*")
                    st.divider()

            # ä¿å­˜æ•°æ®
            user_id = get_current_user_id()
            if user_id:
                topic = extract_topic_from_question(str(st.session_state.quiz_data[0]['question']))
                # å‡è®¾ update_knowledge_point æ”¯æŒåˆ†æ•°è®°å½•ï¼Œæˆ–è€…æ‚¨å¯ä»¥åœ¨æ­¤å¤„è°ƒç”¨ä¸“é—¨çš„ save_quiz_record
                # è¿™é‡Œå¤ç”¨ update_knowledge_pointï¼Œè®¤ä¸º >0.6 å³ä¸ºé€šè¿‡
                is_passed = (score_val >= 0.75)
                update_knowledge_point(user_id, topic, is_correct=is_passed)
                st.toast(f"å·²è®°å½•æŒæ¡çŠ¶æ€ï¼š{status_text}")


# ==================== ä¸»åº”ç”¨é€»è¾‘ ====================

def show_chat_page(user_level, file_path):
    """æ˜¾ç¤ºé—®ç­”åŠ©æ‰‹é¡µé¢"""
    st.title("ğŸ“ æ–°å·¥ç§‘ AI åŠ©æ•™ç³»ç»Ÿ")
    
    # è·å–è§†è§‰æ¨¡å‹çŠ¶æ€ç”¨äºæ˜¾ç¤º
    _vision_provider = get_env_or_secret("VISION_PROVIDER", "zhipu")
    _model_name = VISION_PROVIDERS.get(_vision_provider, {}).get("model", "")
    vision_status = f"ğŸ–¼ï¸ {_model_name}" if get_env_or_secret("VISION_API_KEY") else "ğŸ–¼ï¸ æœªé…ç½®"
    
    user = get_current_user()
    st.caption(f"ğŸ‘¤ {user['username']} | æ¨¡å¼ï¼š{user_level} | å¼•æ“ï¼šDeepSeek | {vision_status}")

    # æ˜¾ç¤ºèŠå¤©è®°å½•
    if "messages" not in st.session_state: 
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): 
            st.markdown(msg["content"], unsafe_allow_html=True)

    # === æ’å…¥æµ‹éªŒåŒºåŸŸ ===
    # åªæœ‰å½“ä¸Šä¼ äº†æ–‡ä»¶æˆ–æœ‰çŸ¥è¯†åº“æ—¶æ‰å…è®¸ç”Ÿæˆæµ‹éªŒ
    if file_path or os.path.exists("./rag_storage"):
        show_quiz_area(file_path, user_level)
    else:
        st.info("ğŸ’¡ ä¸Šä¼  PDF æ•™æåå³å¯ä½¿ç”¨ã€ç”Ÿæˆéšå ‚æµ‹éªŒã€‘åŠŸèƒ½")

    # === æ™®é€šèŠå¤©è¾“å…¥ ===
    if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆæ”¯æŒä¸“ä¸šå…¬å¼è¯¢é—®ï¼‰..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.rerun()

    # å¤„ç†èŠå¤©å›å¤
    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
        last_user_query = st.session_state.messages[-1]["content"]
        
        with st.chat_message("assistant"):
            with st.spinner("ğŸ§  DeepSeek æ­£åœ¨æ€è€ƒ..."):
                try:
                    if not file_path and not os.path.exists("./rag_storage"):
                        error_msg = "è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼  PDF æ•™æï¼"
                        st.error(error_msg)
                        st.session_state.messages.append({"role": "assistant", "content": error_msg})
                    else:
                        loop = st.session_state.loop
                        # æ™®é€šé—®ç­”æ¨¡å¼
                        response = loop.run_until_complete(run_rag(file_path, last_user_query, user_level, is_quiz_mode=False))
                        
                        try:
                            if isinstance(response, str):
                                final_ans = json.loads(response).get("answer", response)
                            else:
                                final_ans = str(response)
                        except:
                            final_ans = str(response)
                        
                        # å†æ¬¡æ¸…æ´—ä»¥é˜²ä¸‡ä¸€
                        final_ans = process_math_format(final_ans)
                        
                        st.markdown(final_ans, unsafe_allow_html=True)
                        st.session_state.messages.append({"role": "assistant", "content": final_ans})
                        
                        # ä¿å­˜é—®ç­”è®°å½•
                        user_id = get_current_user_id()
                        if user_id:
                            topic = extract_topic_from_question(last_user_query)
                            save_chat_history(user_id, last_user_query, final_ans, topic)
                            # é—®ç­”äº’åŠ¨é»˜è®¤ç®—ä½œä¸€æ¬¡æ­£å‘å­¦ä¹ 
                            update_knowledge_point(user_id, topic, is_correct=True)
                        
                except Exception as e:
                    st.error(f"å‘ç”Ÿé”™è¯¯: {e}")
                    st.session_state.messages.append({"role": "assistant", "content": f"Error: {e}"})


def main():
    """ä¸»å‡½æ•°"""
    if not is_logged_in():
        show_login_page()
        return
    
    user = get_current_user()
    
    with st.sidebar:
        st.image("https://img.icons8.com/color/96/artificial-intelligence.png", width=60)
        st.title("âš™ï¸ å­¦ä¹ è®¾ç½®")
        
        page = st.radio("ğŸ“ å¯¼èˆª", ["ğŸ’¬ é—®ç­”åŠ©æ‰‹", "ğŸ“Š å­¦ä¹ ç”»åƒ"], index=0)
        st.divider()
        
        user_level = st.radio("æˆ‘æ˜¯è°ï¼Ÿ", 
            ["ğŸ‘¶ åˆå­¦è€… (é€šä¿—æ˜“æ‡‚)", "ğŸ‘¨â€ğŸ“ æœ¬ç§‘ç”Ÿ (ä¸“ä¸šæ¨å¯¼)", "ğŸ‘¨â€ğŸ”¬ é¢†åŸŸä¸“å®¶ (æ·±åº¦ç ”è®¨)"], index=1)
        st.divider()
        
        st.header("ğŸ“‚ çŸ¥è¯†åº“")
        uploaded_file = st.file_uploader("ä¸Šä¼ æ•™æ (PDF)", type=["pdf"])
        
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºçŸ¥è¯†åº“ç¼“å­˜"):
            import shutil
            if os.path.exists("./rag_storage"): shutil.rmtree("./rag_storage")
            if os.path.exists("./output"): shutil.rmtree("./output")
            # æ¸…é™¤æµ‹éªŒç¼“å­˜
            if "quiz_data" in st.session_state: del st.session_state.quiz_data
            st.success("ç¼“å­˜å·²æ¸…ç©ºï¼è¯·é‡æ–°ä¸Šä¼ æ–‡ä»¶ã€‚")
        
        show_user_info_sidebar()
        
        user_id = get_current_user_id()
        if user_id:
            show_mini_profile_card(user_id)
    
    # å¤„ç†æ–‡ä»¶è·¯å¾„
    file_path = None
    if uploaded_file:
        os.makedirs("uploads", exist_ok=True)
        file_path = os.path.join("uploads", uploaded_file.name)
        if not os.path.exists(file_path):
            with open(file_path, "wb") as f: 
                f.write(uploaded_file.getbuffer())
    elif os.path.exists("uploads") and len(os.listdir("uploads")) > 0:
        file_path = os.path.join("uploads", os.listdir("uploads")[0])
    
    # è·¯ç”±
    if page == "ğŸ’¬ é—®ç­”åŠ©æ‰‹":
        show_chat_page(user_level, file_path)
    elif page == "ğŸ“Š å­¦ä¹ ç”»åƒ":
        user_id = get_current_user_id()
        if user_id:
            show_profile_page(user_id)
        else:
            st.error("æ— æ³•è·å–ç”¨æˆ·ä¿¡æ¯")

if __name__ == "__main__":
    main()